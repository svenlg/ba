{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c31999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from get_data_tensors import get_laws\n",
    "\n",
    "# [PAD]  Padding token 512 tokens per seqences                          0\n",
    "# [UNK]  Used when a word is unknown to Bert                          100\n",
    "# [CLS]  Appears at the start of every sequence                       101\n",
    "# [SEP]  Indicates a seperator - between and end of sequences token   102\n",
    "# [MASK] Used when masking tokens, masked language modelling (MLM)    103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf199453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Change(name):\n",
    "    \n",
    "    se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Law(name):\n",
    "    \n",
    "    fname = '../Data_Laws/'\n",
    "    law_names = np.loadtxt(fname + 'done_with.txt', dtype=str, encoding='utf-8')\n",
    "    #np.random.shuffle(laws)\n",
    "    \n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.changes = []\n",
    "        \n",
    "    def num_changes(self):\n",
    "        return len(self.changes)\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_laws(split=0.9):\n",
    "        ten = []\n",
    "        \n",
    "        num_data_training = int(split*len(laws))\n",
    "    \n",
    "        for i in range(num_data):\n",
    "            print(laws[i])\n",
    "            ten.append(get_old_change_new(laws[i]))\n",
    "    \n",
    "        return ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb29634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(ocn):\n",
    "    \n",
    "    input_ids = torch.from_numpy(np.load(ocn))\n",
    "    mask = torch.ones(input_ids.size())\n",
    "    \n",
    "    input_id_chunks = input_ids.split(510)\n",
    "    mask_chunks = mask.split(510)\n",
    "    \n",
    "    chunksize = 512\n",
    "    \n",
    "    input_id_chunks = list(input_id_chunks) \n",
    "    mask_chunks = list(mask_chunks) \n",
    "    \n",
    "    for i in range(len(input_id_chunks)):\n",
    "        input_id_chunks[i] = torch.cat([\n",
    "            torch.Tensor([101]),input_id_chunks[i],torch.Tensor([102])\n",
    "        ])\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            torch.Tensor([1]),mask_chunks[i],torch.Tensor([1])\n",
    "        ])\n",
    "        \n",
    "        # get required padding length\n",
    "        pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "        \n",
    "        # check if tensor length satisfies required chunk size\n",
    "        if pad_len > 0:\n",
    "            \n",
    "            # if padding length is more than 0, we must add padding\n",
    "            input_id_chunks[i] = torch.cat([\n",
    "                input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "            mask_chunks[i] = torch.cat([\n",
    "                mask_chunks[i], torch.Tensor([0] * pad_len)\n",
    "            ])\n",
    "            \n",
    "    input_ids = torch.stack(input_id_chunks)\n",
    "    attentions_mask = torch.stack(mask_chunks)\n",
    "    \n",
    "    input_dict = {\n",
    "        'input_ids': input_ids.long(),\n",
    "        'attention_mask': attentions_mask.int()\n",
    "    }\n",
    "    \n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5181c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_change_new(law):\n",
    "\n",
    "    law = str(law)\n",
    "    fname = '../Data_Laws/' + law + '/'\n",
    "    changes = np.loadtxt(fname + 'changes.txt', dtype=str, encoding='utf-8')\n",
    "    \n",
    "    ten_law = []\n",
    "    \n",
    "    if changes.shape == ():\n",
    "        change = str(changes)\n",
    "        old = get_tensors(fname + change + '/old.npy')\n",
    "        cha = get_tensors(fname + change + '/change.npy')\n",
    "        new = get_tensors(fname + change + '/new.npy')\n",
    "        ocn = (old,cha,new)\n",
    "        ten_law.append(ocn)\n",
    "        return ten_law\n",
    "    \n",
    "    for change in changes:\n",
    "        change = str(change)\n",
    "        \n",
    "        if law == 'KWG' and change == 'Nr7_2020-12-29':\n",
    "            continue\n",
    "            \n",
    "        old = get_tensors(fname + change + '/old.npy')\n",
    "        cha = get_tensors(fname + change + '/change.npy')\n",
    "        new = get_tensors(fname + change + '/new.npy')\n",
    "        ocn = (old,cha,new)\n",
    "        ten_law.append(ocn)\n",
    "        \n",
    "    return ten_law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f29654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_laws()\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a97edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_task(data):\n",
    "    data_length = len(data)\n",
    "    \n",
    "    out = []\n",
    "    for law in data:\n",
    "        for change in law:\n",
    "            old, change, new = change\n",
    "            out.append(old)\n",
    "            out.append(change)\n",
    "            out.append(new)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3daa8d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BetrVG\n",
      "AufenthG\n",
      "GKG\n",
      "UrhG\n",
      "KVAV\n",
      "IfSG\n"
     ]
    }
   ],
   "source": [
    "data = get_laws(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4547849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = masking_task(data)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa382d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471a0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739eb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfe4b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LawDatasetForMasking(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        data = self.masking_task(data)\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def masking_task(self, data):\n",
    "        out = []\n",
    "        for law in data:\n",
    "            for change in law:\n",
    "                old, change, new = change\n",
    "                out.append(old)\n",
    "                out.append(change)\n",
    "                out.append(new)\n",
    "        return out\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19867dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = LawDatasetForMasking(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61a3300a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 29977, 13981,  ...,   311,  3461,   102],\n",
       "         [  101,   132,   195,  ...,  9837,  2820,   102],\n",
       "         [  101, 30889,  2506,  ..., 22672, 12842,   102],\n",
       "         ...,\n",
       "         [  101,  5607,   197,  ...,  5465,   566,   102],\n",
       "         [  101,  9837, 29519,  ..., 18191,   222,   102],\n",
       "         [  101, 16081,  4884,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2e0aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(data)) # list: Gesetzten die genutzt werden\n",
    "# print(len(data))  # int(split*len(laws))\n",
    "\n",
    "# print(type(data[0])) # list: Changes die es gab pro Gesetz\n",
    "# print(len(data[0]))  # Num an Changes\n",
    "      \n",
    "# print(type(data[0][0])) # tuple: old, change, new\n",
    "# print(len(data[0][0]))  # 3\n",
    "\n",
    "# print(type(data[0][0][0])) # dict: key: ('input_ids', 'attention_mask') values: there pt_tensor representation\n",
    "\n",
    "# print(data[0][0][0]['input_ids'].shape) #shape = (__,512)\n",
    "# print(data[0][0][0]['input_ids']) #pt_tensor long: attual data\n",
    "# print(data[0][0][0]['attention_mask']) #pt_tensor int: only 1 (attention) or 0 (no attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dde0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
